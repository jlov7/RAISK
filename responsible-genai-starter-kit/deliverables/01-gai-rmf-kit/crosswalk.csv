control_id,pattern,function,nist_reference,action,lifecycle_stage,owner_role,required_artifacts
CA-GOV-01,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Govern,AI 600-1 Section 3.1.1,"Define code assistant acceptable use policy (permitted languages, repositories, IP restrictions)",design,Legal / CISO,Code assistant AUP; Legal review sign-off
CA-GOV-02,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Govern,AI 600-1 Section 3.1.2,"Designate responsible party for code assistant security (monitoring, incidents)",design,Engineering Manager,RACI matrix; Escalation contacts
CA-GOV-03,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Govern,AI 600-1 Section 2.8 (Value Chain),"Review vendor contracts for data usage, retention, and IP ownership",design,Procurement / Legal,Vendor contract with data processing addendum; Privacy impact assessment
CA-MAP-01,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Map,AI 600-1 Section 3.2.1,Inventory which repositories/codebases are accessible to code assistant,design,DevOps / Security,Repo access list; Data classification labels (public/internal/confidential)
CA-MAP-02,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Map,AI 600-1 Section 2.3 (Data Privacy),"Identify secrets/credentials in accessible codebases (API keys, passwords)",design,Security Team,"Secret scanning report (e.g., TruffleHog, GitGuardian); Remediation plan"
CA-MAP-03,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Map,AI 600-1 Section 2.7 (Information Integrity),"Map risk of code assistant suggesting vulnerable patterns (SQL injection, XSS)",design,AppSec Team,Threat model for code generation (see /docs/threat-model.md); OWASP Top 10 crosswalk
CA-MAP-04,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Map,AI 600-1 Section 2.8 (Value Chain),Assess risk of code assistant generating copyleft or GPL code,design,Legal / Open Source Program Office,License compliance policy; Legal guidance on AI-generated code
CA-MEAS-01,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Measure,AI 600-1 Section 3.3.1,"Establish baseline code quality metrics (bug rate, security vulnerabilities)",development,QA / AppSec,Pre-deployment SAST scan results; Defect density metrics
CA-MEAS-02,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Measure,AI 600-1 Section 2.7 (Information Integrity),Scan code assistant suggestions for known vulnerabilities (SAST on AI-generated code),development,AppSec,"SAST integration (e.g., Semgrep, CodeQL); Weekly scan reports"
CA-MEAS-03,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Measure,AI 600-1 Section 2.8 (Value Chain),Detect license-incompatible code in AI suggestions,development,Legal / DevOps,"License scanner (e.g., FOSSA, Black Duck); Violation reports"
CA-MEAS-04,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Measure,AI 600-1 Section 3.3.2,Monitor secret leakage in AI-generated code,development,Security Team,"Secret detection in CI (pre-commit hooks, GitHub Advanced Security); Incident logs"
CA-MEAS-05,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Measure,AI 600-1 Section 3.3.3,"Red-team code assistant for adversarial prompt injection (e.g., 'generate backdoor')",development,Security Researcher,Red team report with attack transcripts; Remediation plan
CA-MGT-01,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Manage,AI 600-1 Section 3.4.1,Require human code review for all AI-generated code,development,Engineering Manager,Code review policy update; Training for reviewers on AI-specific risks
CA-MGT-02,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Manage,AI 600-1 Section 3.4.2,Enable audit logging for all code assistant interactions,deployment,DevOps,"Logging configuration (user, timestamp, prompt, suggestion); Log retention policy (90 days minimum)"
CA-MGT-03,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Manage,AI 600-1 Section 3.4.3,"Deploy pre-commit hooks to block secrets, vulnerabilities, license violations",deployment,DevOps,"Pre-commit config (e.g., detect-secrets, Semgrep, FOSSA); Developer onboarding docs"
CA-MGT-04,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Manage,AI 600-1 Section 3.4.4,"Establish incident response plan for code assistant security events (secret leak, vuln introduction)",deployment,Security Team,Code assistant incident runbook; Tabletop exercise report
CA-MGT-05,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Manage,AI 600-1 Section 3.4.5,Monitor code assistant adoption and flag high-risk usage patterns,monitoring,Engineering Analytics,"Usage dashboard (suggestions/day, acceptance rate by repo); Anomaly detection rules (e.g., 100% acceptance rate = insufficient review)"
CA-MGT-06,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Manage,AI 600-1 Section 3.4.6,Provide developer training on secure use of code assistants,deployment,Security Awareness Team,"Training module (security risks, license review, human oversight); Completion certificates"
CA-MGT-07,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Manage,AI 600-1 Section 3.4.7,"Disable code assistant access for high-security repos (e.g., crypto, auth, payment)",deployment,CISO,"High-security repo list; Access control enforcement (e.g., via GitHub Enterprise policies)"
CA-MGT-08,"AI-Powered Code Assistant (e.g., GitHub Copilot, Cursor, internal tools)",Manage,AI 600-1 Section 2.7 (Information Integrity),Implement tool-use sandboxing if code assistant has execution capabilities,deployment,Platform Security,"Sandbox config (containerized, network-isolated); Breakout testing report"
FT-GOV-01,Fine-Tuning & LoRA (Low-Rank Adaptation),Govern,AI 600-1 Section 3.1.1,"Define model training approval workflow (who can train, on what data, for what purpose)",design,ML Governance Board,Training request template; Approval chain documentation
FT-GOV-02,Fine-Tuning & LoRA (Low-Rank Adaptation),Govern,AI 600-1 Section 3.1.2,Establish compute budget and environmental impact targets,design,Infrastructure Lead,"Carbon footprint estimate (e.g., via ML CO2 Impact tool); Compute quota allocation"
FT-GOV-03,Fine-Tuning & LoRA (Low-Rank Adaptation),Govern,AI 600-1 Section 2.4 (Environmental Impact),"Prefer efficient training methods (LoRA, QLoRA) over full fine-tuning when feasible",design,ML Engineer,Training method decision log; Efficiency comparison (LoRA vs full FT)
FT-MAP-01,Fine-Tuning & LoRA (Low-Rank Adaptation),Map,AI 600-1 Section 3.2.1,"Document training data provenance (source, licensing, consent)",design,Data Governance,Data lineage document; License compatibility matrix
FT-MAP-02,Fine-Tuning & LoRA (Low-Rank Adaptation),Map,AI 600-1 Section 2.3 (Data Privacy),Classify training data for PII/PHI; apply anonymization if required,design,Privacy Engineer,"PII scan report; Anonymization technique documentation (k-anonymity, differential privacy)"
FT-MAP-03,Fine-Tuning & LoRA (Low-Rank Adaptation),Map,AI 600-1 Section 2.2 (Bias/Fairness),Assess training data for demographic representation and bias,design,Fairness/Ethics Team,Dataset bias report (fairness metrics by protected attributes); Mitigation plan for underrepresented groups
FT-MAP-04,Fine-Tuning & LoRA (Low-Rank Adaptation),Map,AI 600-1 Section 2.6 (Dangerous Content),"Scan training data for harmful content (violence, CSAM, extremism)",design,Trust & Safety,Content moderation report (automated + human review); Removal logs
FT-MEAS-01,Fine-Tuning & LoRA (Low-Rank Adaptation),Measure,AI 600-1 Section 3.3.1,Establish baseline pre-training performance on evaluation suite,development,ML Engineer,"Pre-training eval report (task accuracy, perplexity); Eval dataset versioned in Git"
FT-MEAS-02,Fine-Tuning & LoRA (Low-Rank Adaptation),Measure,AI 600-1 Section 3.3.2,"Run safety evals post-training (refusal, toxicity, bias)",development,ML Engineer,Safety eval report (D2 harness); Comparison to base model safety scores
FT-MEAS-03,Fine-Tuning & LoRA (Low-Rank Adaptation),Measure,AI 600-1 Section 2.2 (Bias),"Measure fairness metrics post-training (equalized odds, demographic parity)",development,Fairness Team,Fairness eval report; Disaggregated performance by protected attributes
FT-MEAS-04,Fine-Tuning & LoRA (Low-Rank Adaptation),Measure,AI 600-1 Section 2.3 (Data Privacy),"Test for training data extraction (membership inference, regurgitation)",development,Security Researcher,Privacy attack test report; Mitigation plan if extraction successful
FT-MEAS-05,Fine-Tuning & LoRA (Low-Rank Adaptation),Measure,AI 600-1 Section 2.7 (Information Integrity),Evaluate model for hallucination/confabulation on domain-specific queries,development,Domain Expert + ML Engineer,Hallucination eval (factual consistency scoring); Test dataset with ground-truth answers
FT-MGT-01,Fine-Tuning & LoRA (Low-Rank Adaptation),Manage,AI 600-1 Section 3.4.1,"Version-control training scripts, configs, and hyperparameters",development,ML Engineer,Git repo with all training code; Config files (YAML/JSON) for reproducibility
FT-MGT-02,Fine-Tuning & LoRA (Low-Rank Adaptation),Manage,AI 600-1 Section 3.4.2,"Track training runs with experiment management (MLflow, Weights & Biases)",development,ML Ops,"Experiment logs (loss curves, eval metrics); Model artifact registry"
FT-MGT-03,Fine-Tuning & LoRA (Low-Rank Adaptation),Manage,AI 600-1 Section 3.4.3,Generate model card for fine-tuned model,deployment,ML Engineer,Completed model card (see D1 template); Published to internal model hub
FT-MGT-04,Fine-Tuning & LoRA (Low-Rank Adaptation),Manage,AI 600-1 Section 2.8 (Value Chain),Sign model weights and publish provenance (SLSA),deployment,ML Ops,"Signed model artifact (e.g., via Sigstore); SLSA provenance attestation (see D3)"
FT-MGT-05,Fine-Tuning & LoRA (Low-Rank Adaptation),Manage,AI 600-1 Section 3.4.5,Deploy continuous monitoring for model performance drift,monitoring,ML Ops,"Monitoring dashboard (accuracy, latency, fairness); Alerting rules (accuracy drops >5%)"
FT-MGT-06,Fine-Tuning & LoRA (Low-Rank Adaptation),Manage,AI 600-1 Section 3.4.6,Establish model rollback procedure for safety/performance regressions,deployment,DevOps,Rollback runbook; Blue-green deployment config
FT-MGT-07,Fine-Tuning & LoRA (Low-Rank Adaptation),Manage,AI 600-1 Section 3.4.7,Retain training data and models per data retention policy,monitoring,Data Governance,Data retention schedule; Deletion logs
RAG-GOV-01,Retrieval-Augmented Generation (RAG),Govern,AI 600-1 Section 3.1.1,Establish AI governance committee with authority over RAG deployments,design,CISO / Chief AI Officer,"Governance charter documenting roles, responsibilities, and escalation paths; Meeting minutes from initial governance kickoff"
RAG-GOV-02,Retrieval-Augmented Generation (RAG),Govern,AI 600-1 Section 3.1.2,"Define acceptable use policy for RAG system (permitted queries, prohibited content)",design,Legal / Compliance,Acceptable Use Policy (AUP) document; User training completion records
RAG-GOV-03,Retrieval-Augmented Generation (RAG),Govern,AI 600-1 Section 3.1.3,Assign data steward responsible for vector database content quality and provenance,design,Data Governance Lead,RACI matrix with named data steward; Data quality SLA
RAG-MAP-01,Retrieval-Augmented Generation (RAG),Map,AI 600-1 Section 3.2.1,"Document RAG system context: intended use, user base, sensitivity of data",design,Product Manager / ML Lead,System context document (use Model Card template); Data classification labels (public/internal/confidential)
RAG-MAP-02,Retrieval-Augmented Generation (RAG),Map,AI 600-1 Section 3.2.2,"Inventory all data sources feeding vector database (documents, APIs, databases)",design,Data Engineer,Data lineage diagram; Source system access logs
RAG-MAP-03,Retrieval-Augmented Generation (RAG),Map,AI 600-1 Section 2.3 (Data Privacy),Identify PII/PHI in retrieval corpus; classify sensitivity,design,Privacy Officer,PII scan report (automated + manual review); Data minimization plan
RAG-MAP-04,Retrieval-Augmented Generation (RAG),Map,AI 600-1 Section 2.7 (Information Integrity),"Map prompt injection attack surface (user inputs, retrieval context, system prompts)",design,Security Architect,Threat model (see /docs/threat-model.md); Attack tree diagram
RAG-MEAS-01,Retrieval-Augmented Generation (RAG),Measure,AI 600-1 Section 3.3.1,"Establish baseline performance metrics (retrieval precision/recall, answer quality)",development,ML Engineer,Golden evaluation dataset (100+ Q&A pairs); Baseline test report
RAG-MEAS-02,Retrieval-Augmented Generation (RAG),Measure,AI 600-1 Section 3.3.2,Deploy automated refusal-rate scoring (system refuses harmful/out-of-scope queries),development,ML Engineer,Refusal-rate eval integrated in D2 harness; Test dataset with 50+ adversarial prompts
RAG-MEAS-03,Retrieval-Augmented Generation (RAG),Measure,AI 600-1 Section 2.3 (Data Privacy),Deploy automated PII detection on RAG outputs,development,ML Engineer,PII scorer integrated in D2 harness; Test report showing 0% PII leakage on golden dataset
RAG-MEAS-04,Retrieval-Augmented Generation (RAG),Measure,AI 600-1 Section 2.7 (Information Integrity),Measure citation accuracy (does RAG cite sources correctly?),development,ML Engineer,Citation accuracy eval (see D2 harness); Test report
RAG-MEAS-05,Retrieval-Augmented Generation (RAG),Measure,AI 600-1 Section 2.2 (Confabulation/Hallucination),Red-team for prompt injection vulnerabilities,development,Security Team,Red team report with attack transcripts; Remediation plan for successful attacks
RAG-MGT-01,Retrieval-Augmented Generation (RAG),Manage,AI 600-1 Section 3.4.1,Implement input validation and sanitization for user queries,development,Backend Engineer,"Input validation rules (length limits, character filters, blocked patterns); Code review approval"
RAG-MGT-02,Retrieval-Augmented Generation (RAG),Manage,AI 600-1 Section 3.4.2,Deploy output filtering to remove PII before displaying to users,development,ML Engineer,PII redaction service (regex + NER model); Test report showing redaction effectiveness
RAG-MGT-03,Retrieval-Augmented Generation (RAG),Manage,AI 600-1 Section 3.4.3,Implement rate limiting and resource quotas per user/tenant,deployment,Platform Engineer,"Rate limiting configuration (e.g., 10 queries/minute); Load test results"
RAG-MGT-04,Retrieval-Augmented Generation (RAG),Manage,AI 600-1 Section 3.4.4,Enable audit logging for all queries and responses,deployment,DevOps / SRE,"Centralized logging (e.g., ELK, Splunk); Log retention policy (90 days minimum)"
RAG-MGT-05,Retrieval-Augmented Generation (RAG),Manage,AI 600-1 Section 3.4.5,"Establish incident response plan for AI safety events (PII leak, jailbreak, data poisoning)",deployment,Security Team,AI incident runbook; Tabletop exercise report
RAG-MGT-06,Retrieval-Augmented Generation (RAG),Manage,AI 600-1 Section 3.4.6,Deploy continuous monitoring for model/retrieval drift,monitoring,ML Ops,"Monitoring dashboard (retrieval precision, answer quality); Alerting rules (e.g., precision drops >10%)"
RAG-MGT-07,Retrieval-Augmented Generation (RAG),Manage,AI 600-1 Section 3.4.7,Implement vector database access controls (prevent cross-tenant data leakage),deployment,Platform Engineer,Access control policy (RBAC or ABAC); Penetration test report (attempt cross-tenant access)
RAG-MGT-08,Retrieval-Augmented Generation (RAG),Manage,AI 600-1 Section 2.8 (Value Chain),"Vet third-party dependencies (vector DB, embedding API, LLM provider)",design,Procurement / Security,Vendor risk assessment; SBOMs for all components (see D3)
